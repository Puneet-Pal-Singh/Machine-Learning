{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WHZWNjIMM4jfgZqz13PhL9wmP4rQEZnw",
      "authorship_tag": "ABX9TyMu9Oq82/1NHWUdKHB+kZ5w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Puneet-Pal-Singh/Machine-Learning/blob/master/7.%20Natural%20Language%20Processing/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ3uIJlcFO7J",
        "colab_type": "text"
      },
      "source": [
        "# Bags of Words Model\n",
        "It is a Text learning process\n",
        "\n",
        "The table is a matrix and a matrix containing a lot of zeroes is called a sparse matrix.And the fact that we have a lot of zeroes is called sparsity and that's a very common notion in machine learning\n",
        "\n",
        "The bag of words model is basically to simplify all the reviews clean all the reviews to simplify the words and try to minimize the number of words.\n",
        "And it's also about creating the sparse matrix through the process of tokenization tokenization is the process of you know taking all the different words of the review and creating one column for each of these words\n",
        "\n",
        "we will be able to apply our classification models to predict for each new review. If it's positive or negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_tJe57NTMzm",
        "colab_type": "text"
      },
      "source": [
        "## Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8SqZWwoTrO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njvxvf3RTj2a",
        "colab_type": "text"
      },
      "source": [
        "## Importing the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6D4v91NTjy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/My Drive/Machine Learning/Machine Learning A-Z Template Folder/Part 7 - Natural Language Processing/Section 36 - Natural Language Processing/Restaurant_Reviews.tsv\",\n",
        "                      delimiter = '\\t',\n",
        "                      quoting = 3 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbnAY7cJUWlT",
        "colab_type": "text"
      },
      "source": [
        "Use of TSV file = Delimiter is set as '\\t' representing tab as space between words rather than ',\n",
        "' which is used in csv file and we have also seen Quotes in dataset therefore quoting = 3 is set for ignoring quotes in the dataset      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBXmGJTKjqDX",
        "colab_type": "code",
        "outputId": "5711424d-fb5e-469c-bc59-cf026200e2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3ExUboyUWfA",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1UbYqqfijBH",
        "colab_type": "code",
        "outputId": "f04c3248-f368-4757-8ac4-8c12d64f1016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install regex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWl54dHUY3Yn",
        "colab_type": "code",
        "outputId": "65c18803-243e-4b08-a4d1-b4fd33b9f6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []                        # List is created\n",
        "for i in range(0, 1000):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  ps = PorterStemmer()               # Object\n",
        "  review = [ps.stem(word) for word in review \n",
        "            if not word in set(stopwords.words('english'))]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-EEbGWsZkv7",
        "colab_type": "text"
      },
      "source": [
        "re - Regex Package - Regular expressions\n",
        "\n",
        "> re package is used for removing the unwanted text which not helps us to identify that the review is negative or positive \n",
        "\n",
        "\n",
        "---\n",
        "Step - 1\n",
        "\n",
        "*   First parameter - Tells letters not to remove.\n",
        "*   Second parameter - Space is given wherever letters are removed.\n",
        "*   Third parameter - Tells the line number.\n",
        "\n",
        "Step - 2\n",
        "\n",
        "*   Upper case letters are converted to lower to lower case\n",
        "\n",
        "Step - 3\n",
        "\n",
        "* nltk package and stopwords package are imported which downloads a list of words which are generically irrelevant.\n",
        "\n",
        "Step - 4\n",
        "\n",
        "*  split function converts words/strings into list \n",
        "*  loop is implemented for checking all words and set function is used for faster outcome of the algo.\n",
        "\n",
        "Step - 5\n",
        " [Performing Stemming]\n",
        "* import Porter Stemmer library and applied it the word by making ps object \n",
        "  which is used in sparsity or making sparse matrix.\n",
        "  loved -> love\n",
        "\n",
        "Step - 6\n",
        "\n",
        "* Joining the Strings.\n",
        "\n",
        "............End of Cleaning Process.............\n",
        "\n",
        "Step - 7\n",
        " \n",
        "* Implement it on all reviews which is 1000 reviews.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0pxPDpab40m",
        "colab_type": "code",
        "outputId": "31e4b99f-2465-4b0f-91e5-217182d67faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset['Review'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wow... Loved this place.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is1V98zDoRdf",
        "colab_type": "code",
        "outputId": "8574748c-df2c-4963-ddbc-5e5eeb1975fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "review"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wast enough life pour salt wound draw time took bring check'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuuR6OnhD8SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XuiQ4rhoZx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install jupyter_contrib_nbextensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp9-3s6BeT9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# jupyter contrib nbextension install --user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy7xMtZIkPCy",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Bag of Words model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEj_1GTSkO8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "# Turned into sparse matrix\n",
        "y = dataset.iloc[:, 1].values     # depedent variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brx8TeNGlLil",
        "colab_type": "code",
        "outputId": "86390277-85b1-4d8b-ced8-d682d6f823a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.size \n",
        "# [ 1500 * 1000 ] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHxPB-wLk4Zq",
        "colab_type": "text"
      },
      "source": [
        "* iloc is to take the index of the dependent variable column.\n",
        "* max_features is used to reduce sparsity in matrix or filtering, therefore max_features = 1500\n",
        "* Each line here corresponds to one specific review and for each of those reviews well each of the conqure response to one word and we get a zero if the word doesn't appear in the review and a 1 if the word appears in the review.\n",
        "And so basically that gives us a classification model because now we will train a machine or any model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F651F81Wqltv",
        "colab_type": "text"
      },
      "source": [
        "## Implementing Naive Bayes Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Tn6FdBr1wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "# !pip install scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxPBH6egr1ls",
        "colab_type": "code",
        "outputId": "905b17e7-4092-4f68-f56b-b037ff2a1da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Fitting Naive Bayes to the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEd9oQ1sBbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H0Vk5Fse4bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Hq709Krav0",
        "colab_type": "code",
        "outputId": "3fd9eef7-44ec-4c22-d94b-3992710a0e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[55, 42],\n",
              "       [12, 91]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_GRi__FhpbN",
        "colab_type": "text"
      },
      "source": [
        "42 + 12 = 54 Incorrect Predictions\n",
        "\n",
        "55 + 91 = 146 Correct Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF-GBE3MrcEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e4ed707-ff69-41d8-f8cd-5cc4a1b45345"
      },
      "source": [
        "(55 + 91) / 200 \n",
        "# As there are 200 test sets"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nb0opVllFaf",
        "colab_type": "text"
      },
      "source": [
        "Therefore accuracy is 73 % ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRtJ5H8_k7C3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}